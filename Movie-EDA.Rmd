---
title: "Movie Revenue"
output: 
  html_document:
    toc: TRUE
    theme: cerulean
    number_sections: TRUE
    code_folding: show
---


Packages used for analysis
```{r, message = FALSE}
library(tidyverse)
library(caret)
library(Amelia)
library(stringr)
library(DataExplorer)
library(fastDummies)
library(forcats)
library(purrr)
library(lubridate)
```

# Read in the data

```{r, warning=FALSE}
movie_train <- read.csv("train.csv", stringsAsFactors = FALSE, na.strings = c("", NA))
movie_test <- read.csv("test.csv", stringsAsFactors = FALSE, na.strings = c("", NA))
movie_data <- bind_rows(movie_train, movie_test)

colnames(movie_data)[1] <- "id"
colnames(movie_train)[1] <- "id"
colnames(movie_test)[1] <- "id"
```

## Initial Plots

```{r, message=FALSE}
# Plots of numeric variables
ggplot(movie_data, aes(x = popularity, y = revenue)) + geom_point() + geom_smooth(method = "loess", se = FALSE) + xlim(0, 300)
ggplot(movie_data, aes(x = runtime, y = revenue)) + geom_point() + geom_smooth(method = "loess", se = FALSE)
ggplot(movie_data, aes(x = budget, y = revenue)) + geom_point() + geom_smooth(method = "loess", se = FALSE)

# Plot of how many values are missing
missmap(movie_data, col = c("red", "navyblue"))
plot_missing(movie_data)
```

# Data Cleaning

## Initial Variable Dropping

Dropping some variables that we don't need at all initially

```{r}
movie_data <- movie_data %>% select(-imdb_id, -original_title, -overview, -poster_path, -status)

# Insert the release data for the one missing value
movie_data[is.na(movie_data$release_date),]$release_date <- "05/01/00"
# Change release date to a date
movie_data$release_date <- parse_date_time2(movie_data$release_date, orders = "%m%d%y", cutoff_2000 = 20L)
```

## Categorical variables

For each of these features, there is a higher average revenue when not NA than when NA

```{r}
# Analyzing features with many NAs

movie_nas <- movie_train %>%
  select(Keywords, tagline, homepage, belongs_to_collection, revenue) %>%
  mutate_at(.funs = list(cat = ~ifelse(is.na(.), 0, 1)), 
            .vars = c("Keywords", "tagline", "homepage",
                      "belongs_to_collection"))

# Keywords
mean(movie_nas[movie_nas$Keywords_cat == 1,]$revenue, na.rm = TRUE)
mean(movie_nas[movie_nas$Keywords_cat == 0,]$revenue, na.rm = TRUE)
boxplot(revenue~Keywords_cat, data = movie_nas)

# Tagline
mean(movie_nas[movie_nas$tagline_cat == 1,]$revenue)
mean(movie_nas[movie_nas$tagline_cat == 0,]$revenue)
boxplot(revenue~tagline_cat, data = movie_nas)

# Homepage
mean(movie_nas[movie_nas$homepage_cat == 1,]$revenue)
mean(movie_nas[movie_nas$homepage_cat == 0,]$revenue)
boxplot(revenue~homepage_cat, data = movie_nas)

# Collection
mean(movie_nas[movie_nas$belongs_to_collection_cat == 1,]$revenue)
mean(movie_nas[movie_nas$belongs_to_collection_cat == 0,]$revenue)
boxplot(revenue~belongs_to_collection_cat, data = movie_nas)

# Add indicator columns to main data
movie_data <- movie_data %>% 
  mutate_at(.funs = list(ind = ~ifelse(is.na(.), 0, 1)),
            .vars = c("Keywords", "tagline", "homepage",
                      "belongs_to_collection"))

# Drop columns
movie_data <- movie_data %>%
  select(-belongs_to_collection, -homepage, -tagline, -Keywords)
```

## Cast and Crew (counts for each)

```{r}
movie_data$cast_count <- str_count(movie_data$cast, "'name':\\s'")
movie_data$crew_count <- str_count(movie_data$crew, "'name':\\s'")

# Impute median for missing crew_count values
movie_data[is.na(movie_data$crew_count),]$crew_count <- median(movie_data$crew_count, na.rm=TRUE)
```

## Original Language

```{r}
# Most of the movies are English, so I'm going to add another indicator variable to specify if the original language was English or not
movie_data <- movie_data %>% mutate(English = ifelse(original_language == "en", 1, 0))

# Drop original langauge column
movie_data <- movie_data %>% select(-original_language)

```

## Function to extract useful data

```{r}
extract_n_most_freq_to_dummy <- function(vect, pattern, name, n_most_pattern_fun, n_most_freq=NULL) {
  
  # Get all vars into a usable list
  var_extractor <- function(x) {
      unlist(str_extract_all(x, pattern=pattern))
  }
  
  if(!is.null(n_most_freq)) {
    n_most_freq <- n_most_freq
    extracted_vars <- lapply(vect, var_extractor) %>%
      unlist()
    
    # Find n most frequently appearing vars
    var_freq <- tibble(var = extracted_vars) %>%
      group_by(var) %>%
      count() %>%
      arrange(desc(n)) %>%
      ungroup() %>%
      filter(!is.na(var)) %>%
      top_n(n_most_freq, n)
    
    # Create new regular expression for most frequently occuring vars
    var_regex <- n_most_pattern_fun(var_freq$var)
    # var_regex <- paste(var_freq$var, collapse="|") %>%
    #   str_replace_all('([^a-zA-Z0-9 |\\-])', '\\\\\\1')
    
    new_vars <- sapply(vect, function(x) {
      unlist(str_extract_all(x, var_regex))
      })
    
    dummy_vars <- qdapTools::mtabulate(new_vars) 
  }
  else {
    extracted_vars <- sapply(vect, var_extractor)
    dummy_vars <- qdapTools::mtabulate(extracted_vars)
  }
  
  colnames(dummy_vars) <- paste0(name, gsub("\\W", "", colnames(dummy_vars)))
  rownames(dummy_vars) <- 1:nrow(dummy_vars)
  
  return(dummy_vars)
}
```

### Spoken Languages

```{r}
pattern <- "(?<=')[:lower:]{2}(?=')"
pattern_fun <- function(x) {
  paste(x, collapse="|") %>%
    paste0("(?<=')(", ., ")")
}
name <- 'Sp_'
n <- 7

dummy_sp <- extract_n_most_freq_to_dummy(movie_data$spoken_languages, pattern, name, pattern_fun, n)

movie_data <- cbind(movie_data, dummy_sp)

# Number of spoken languages
movie_data$Num_Languages <- movie_data %>%
  select(Sp_de:Sp_ru) %>%
  rowSums()
```

### Genres

```{r}
pattern <- "(?<=\')([A-Z])\\w+(.*?)(?=\')"
pattern_fun <- function(x) {
  paste(x, collapse="|")
}
name <- 'Genre'
n <- NULL

dummy_g <- extract_n_most_freq_to_dummy(movie_data$genres, pattern, name, pattern_fun, n)

movie_data <- cbind(movie_data, dummy_g)

# number of genres
movie_data$num_genres <- movie_data %>% select(GenreAction:GenreWestern) %>% rowSums()
```

### Countries

```{r country}
pattern <- "(?<=name': ')[A-Za-z\\s]+"
pattern_fun <- function(x) {
  paste(x, collapse="|")
}
name <- 'Country'
n <- 10

dummy_c <- extract_n_most_freq_to_dummy(movie_data$production_countries, pattern, name, pattern_fun, n)

movie_data <- cbind(movie_data, dummy_c)
```

### Production Companies

```{r}
pattern <- "(?<=name': ')[^']+"
pattern_fun <- function(x) {
  paste(x, collapse="|") %>%
      str_replace_all('([^a-zA-Z0-9 |\\-])', '\\\\\\1')
}
name <- 'Comp'
n <- 30

dummy_comp <- extract_n_most_freq_to_dummy(movie_data$production_companies, pattern, name, pattern_fun, n)

movie_data <- cbind(movie_data, dummy_comp)
```

## Imputation: Runtime

```{r}
# Median imputation for the runtime variable
movie_data[is.na(movie_data$runtime),]$runtime <- median(movie_data[!is.na(movie_data$runtime),]$runtime)
```

## Remove original string variables
```{r}
movie_data_1 <- movie_data %>%
  select(-c(id, genres, production_companies,
            production_countries, spoken_languages, 
            title, cast, crew))
```

# Preprocessing

```{r}
# Split dataset into original train/test split
movie.train.pre <- movie_data_1 %>%
  filter(!is.na(revenue)) %>%
  select(-revenue)
movie.test.pre <- movie_data_1 %>%
  filter(is.na(revenue)) %>% 
  select(-revenue)
```

## PCA Dataset

```{r}
# Remove variables with near-zero variance and reduce dimensionality
train <- preProcess(movie.train.pre, method = c("nzv", "pca"))
movie.train <- predict(train, movie.train.pre)
movie.test <- predict(train, movie.test.pre)

movie.train <- movie.train %>% 
  mutate(revenue = movie_data_1$revenue[!is.na(movie_data_1$revenue)])
```

## No PCA Dataset

```{r}
# Remove variables with near-zero variance and reduce dimensionality
train <- preProcess(movie.train.pre, method = c("nzv", "center", "scale"))
movie.train.nopca <- predict(train, movie.train.pre)
movie.test.nopca <- predict(train, movie.test.pre)

movie.train.nopca <- movie.train.nopca %>% 
  mutate(revenue = movie_data_1$revenue[!is.na(movie_data_1$revenue)])
```

# Predictions

## Prepping for caret library

```{r}
# Using rmsle as scoring function for cross validation fitting
custom_summary <- function(data, lev = NULL, model = NULL) {
  out <- Metrics::rmsle(data[, "obs"], data[, "pred"])
  names(out) <- c("rmsle")
  return(out)
}

myControl <- trainControl(method = "cv",
                          number = 10,
                          summaryFunction = custom_summary)

# Set random seed
set.seed(1989)
```

## Log Random Forest

```{r}
model <- train(log(revenue)~.,
                  data = movie.train,
                  method = "ranger",
                  tuneLength = 5,
                  trControl = myControl,
                  metric = "rmsle",
                  maximize = FALSE); beepr::beep(3)
model

preds <- predict(model, newdata = movie.test) %>% exp()
dat <- data.frame(id = movie_test$id, revenue = preds)
write_csv(dat, "log-rf-preds.csv")
```

## Glmnet

```{r}
model2 <- train(log(revenue)~.,
                data = movie.train,
                method = "glmnet",
                tuneLength = 10,
                trControl = myControl,
                metric ="rmsle",
                maximize = FALSE); beepr::beep(3)
model2

preds <- predict(model2, newdata = movie.test) %>% exp()
dat <- data.frame(id = movie_test$id, revenue = preds)
write_csv(dat, "glmnet-preds.csv")
```

## Bagged MARS

```{r}
model3 <- train(log(revenue)~.,
                data = movie.train,
                method = "bagEarth",
                tuneLength = 5,
                trControl = myControl,
                metric ="rmsle",
                maximize = FALSE); beepr::beep(3)
model3

preds <- predict(model3, newdata = movie.test) %>% exp()
dat <- data.frame(id = movie_test$id, revenue = preds)
write_csv(dat, "mars-preds.csv")
```

## SVM

```{r}
model4 <- train(log(revenue)~.,
                data = movie.train,
                method = "svmRadial",
                tuneLength = 5,
                trControl = myControl,
                metric ="rmsle",
                maximize = FALSE); beepr::beep(3)
model4

preds <- predict(model4, newdata = movie.test) %>% exp()
dat <- data.frame(id = movie_test$id, revenue = preds)
write_csv(dat, "svm-preds.csv")
```

## Random Forest, No PCA (2.15475 score)

```{r}

grid <- expand.grid("mtry" = c(20, 25, 30), "splitrule" = "extratrees", min.node.size = c(1, 3, 5))

model.rf2 <- train(log(revenue)~.,
                  data = movie.train.nopca,
                  method = "ranger",
                  tuneGrid = grid,
                  trControl = myControl,
                  metric = "rmsle",
                  maximize = FALSE); beepr::beep(3)

model.rf2

preds.rf2 <- predict(model.rf2, newdata = movie.test.nopca) %>% exp()
rf.dat2 <- data.frame(id = movie_test[,1], revenue = preds.rf2)
write_csv(rf.dat2, path = "rf_nopca2.csv")

```

## Gradient Boosting Forest, No PCA (2.07568 score)

```{r}
grid <- expand.grid("n.trees"=500, "interaction.depth"=4, "shrinkage"=0.1, "n.minobsinnode"=20)

rfb.mod <- train(log(revenue)~.,
                 data=movie.train.nopca,
                 method="gbm",
                 tuneGrid=grid,
                 trControl=myControl,
                 metric = "rmsle",
                 verbose=F); beepr::beep(3)

preds <- predict(rfb.mod, newdata = movie.test.nopca) %>% exp()
dat <- data.frame(id = movie_test$id, revenue = preds)
write_csv(dat, "rf-gboost-preds.csv")
```

## xgbLinear, No PCA (2.1869 score)

```{r}
myControl <- trainControl(method = "cv",
                          number = 3,
                          summaryFunction = custom_summary)

tunegrid <- expand.grid(nrounds = 60,
                        lambda = .01,
                        alpha = .01,
                        eta = .2)

xgbLinear.model <- train(log(revenue)~.,
                   data = movie.train.nopca,
                   method = "xgbLinear",
                   tuneGrid = tunegrid,
                   trControl = myControl,
                   metric = "rmsle",
                   maximize = FALSE); beepr::beep(3)
xgbLinear.model

preds <- predict(xgbLinear.model, newdata = movie.test.nopca) %>% exp()
dat <- data.frame(id = movie_test$id, revenue = preds)
write_csv(dat, "xgbLinear-preds.csv")
```

## XGB Tree (2.09998 score)

```{r}
tunegrid <- expand.grid(eta = .25,
                        max_depth = 3,
                        colsample_bytree = .9,
                        subsample = .8,
                        nrounds = 100,
                        min_child_weight = 1,
                        gamma = .075)

xgbTree.model <- train(log(revenue)~.,
                   data = movie.train,
                   method = "xgbTree",
                   tuneGrid = tunegrid,
                   trControl = myControl,
                   metric = "rmsle",
                   maximize = FALSE
)
xgbTree.model

preds <- predict(xgbTree.model, newdata = movie.test) %>% exp()
dat <- data.frame(id = movie_test$id, revenue = preds)
write_csv(dat, "xgbTree-preds.csv")
```
